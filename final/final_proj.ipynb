{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 117287,
          "databundleVersionId": 14018857,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31153,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "nathaniel14133437_midterm_CS5173",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grillinr/evolutionary-computing/blob/main/final/final_proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and seed for easier checking"
      ],
      "metadata": {
        "id": "uibqKYOH1C2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.metrics import accuracy_score, fbeta_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "SEED = 5173\n",
        "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda\")\n",
        "print(device)\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:35:17.559153Z",
          "iopub.execute_input": "2025-10-17T00:35:17.559461Z",
          "iopub.status.idle": "2025-10-17T00:35:17.568112Z",
          "shell.execute_reply.started": "2025-10-17T00:35:17.559437Z",
          "shell.execute_reply": "2025-10-17T00:35:17.567065Z"
        },
        "id": "rU8AhTMY1C2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6edce23-4a57-4d36-c74b-59ceaa55a3fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define helper functions"
      ],
      "metadata": {
        "id": "i8xd5F721C2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_with_scaler(data, scaler=None, fit=False):\n",
        "    data = data.dropna()\n",
        "    X = data.drop(columns=[\"id\", \"record\", \"type\"]).values.astype(np.float32)\n",
        "    y = data[\"type\"].astype(\"category\").cat.codes.values\n",
        "\n",
        "    if fit:\n",
        "        X = scaler.fit_transform(X)\n",
        "    else:\n",
        "        X = scaler.transform(X)\n",
        "\n",
        "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "\n",
        "def evaluate(model, X, y, criterion):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(X)\n",
        "        loss = criterion(logits, y)\n",
        "        y_pred = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "    y_true = y.cpu().numpy()\n",
        "    return {\n",
        "        \"loss\": loss.item(),\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"f_beta_macro\": fbeta_score(y_true, y_pred, average=\"macro\", beta=2, zero_division=0)\n",
        "    }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:46:03.730208Z",
          "iopub.execute_input": "2025-10-17T00:46:03.730536Z",
          "iopub.status.idle": "2025-10-17T00:46:03.738421Z",
          "shell.execute_reply.started": "2025-10-17T00:46:03.730511Z",
          "shell.execute_reply": "2025-10-17T00:46:03.73737Z"
        },
        "id": "ZxxTIRWL1C2O"
      },
      "outputs": [],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Model Architecture (DNN)"
      ],
      "metadata": {
        "id": "dTi3Q6241C2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNN(nn.Module):\n",
        "    def __init__(self, input_size=32, hidden=(32, 16, 8), num_classes=5, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        input_dim = input_size\n",
        "\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "            layers.append(nn.Dropout(dropout_rate))\n",
        "            input_dim = h\n",
        "\n",
        "        layers.append(nn.Linear(input_dim, num_classes))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:35:38.736024Z",
          "iopub.execute_input": "2025-10-17T00:35:38.736378Z",
          "iopub.status.idle": "2025-10-17T00:35:38.74276Z",
          "shell.execute_reply.started": "2025-10-17T00:35:38.736352Z",
          "shell.execute_reply": "2025-10-17T00:35:38.741836Z"
        },
        "id": "qzOM0laS1C2P"
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Training loop"
      ],
      "metadata": {
        "id": "8V1SVoBd1C2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "dataset = pd.read_csv(\"/content/train.csv\")\n",
        "train_dataset, val_dataset = train_test_split(dataset, train_size=0.7, random_state=SEED)\n",
        "scaler = StandardScaler()\n",
        "X_train, y_train = prepare_data_with_scaler(train_dataset, scaler, fit=True)\n",
        "X_val, y_val = prepare_data_with_scaler(val_dataset, scaler, fit=False)\n",
        "\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "X_val, y_val = X_val.to(device), y_val.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:46:12.869203Z",
          "iopub.execute_input": "2025-10-17T00:46:12.869487Z",
          "iopub.status.idle": "2025-10-17T00:46:18.983013Z",
          "shell.execute_reply.started": "2025-10-17T00:46:12.869467Z",
          "shell.execute_reply": "2025-10-17T00:46:18.982193Z"
        },
        "id": "Dv6o3n1t1C2Q"
      },
      "outputs": [],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "lr = 1e-3\n",
        "epochs = 1000\n",
        "hidden = (32, 16, 8)\n",
        "dropout_rate = 0.5\n",
        "patience = 100\n",
        "\n",
        "# Create model\n",
        "model = DNN(hidden=hidden, dropout_rate=dropout_rate).to(device)\n",
        "\n",
        "class_counts = train_dataset['type'].value_counts()\n",
        "weights = 1.0 / class_counts.values\n",
        "weights = torch.FloatTensor(weights).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:35:56.034543Z",
          "iopub.execute_input": "2025-10-17T00:35:56.034924Z",
          "iopub.status.idle": "2025-10-17T00:35:56.042659Z",
          "shell.execute_reply.started": "2025-10-17T00:35:56.034863Z",
          "shell.execute_reply": "2025-10-17T00:35:56.041417Z"
        },
        "id": "R3uFXDIH1C2Q"
      },
      "outputs": [],
      "execution_count": 26
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with early stopping\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(X_train)\n",
        "    loss = criterion(out, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss = loss.item()\n",
        "\n",
        "    train_metrics = evaluate(model, X_train, y_train, criterion)\n",
        "    val_metrics = evaluate(model, X_val, y_val, criterion)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "      print(\n",
        "          f\"Epoch {epoch}/{epochs} | \"\n",
        "          f\"train_loss={train_loss:.4f} train_acc={train_metrics['accuracy']:.4f} \"\n",
        "          f\"train_f1={train_metrics['f_beta_macro']:.4f} \"\n",
        "          f\"val_loss={val_metrics['loss']:.4f} val_acc={val_metrics['accuracy']:.4f} \"\n",
        "          f\"val_f1={val_metrics['f_beta_macro']:.4f} \"\n",
        "      )\n",
        "\n",
        "    # Early stopping check\n",
        "    if val_metrics['loss'] < best_val_loss:\n",
        "        best_val_loss = val_metrics['loss']\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:43:03.337535Z",
          "iopub.execute_input": "2025-10-17T00:43:03.337852Z",
          "iopub.status.idle": "2025-10-17T00:43:03.676338Z",
          "shell.execute_reply.started": "2025-10-17T00:43:03.337828Z",
          "shell.execute_reply": "2025-10-17T00:43:03.675024Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEO7m2r11C2R",
        "outputId": "36d05e47-5796-4974-e87f-6e67d2fdf655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/1000 | train_loss=1.3987 train_acc=0.0674 train_f1=0.0546 val_loss=1.3922 val_acc=0.0675 val_f1=0.0557 \n",
            "Epoch 20/1000 | train_loss=1.2662 train_acc=0.0677 train_f1=0.0533 val_loss=1.2205 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 30/1000 | train_loss=1.1273 train_acc=0.0677 train_f1=0.0533 val_loss=1.0182 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 40/1000 | train_loss=1.0116 train_acc=0.0677 train_f1=0.0533 val_loss=0.8405 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 50/1000 | train_loss=0.9290 train_acc=0.0677 train_f1=0.0533 val_loss=0.7303 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 60/1000 | train_loss=0.8862 train_acc=0.0677 train_f1=0.0533 val_loss=0.6775 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 70/1000 | train_loss=0.8514 train_acc=0.0677 train_f1=0.0533 val_loss=0.6510 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 80/1000 | train_loss=0.8295 train_acc=0.0677 train_f1=0.0533 val_loss=0.6332 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 90/1000 | train_loss=0.8015 train_acc=0.0677 train_f1=0.0533 val_loss=0.6199 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 100/1000 | train_loss=0.7819 train_acc=0.0677 train_f1=0.0533 val_loss=0.6089 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 110/1000 | train_loss=0.7619 train_acc=0.0677 train_f1=0.0533 val_loss=0.5987 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 120/1000 | train_loss=0.7487 train_acc=0.0677 train_f1=0.0533 val_loss=0.5885 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 130/1000 | train_loss=0.7270 train_acc=0.0677 train_f1=0.0533 val_loss=0.5783 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 140/1000 | train_loss=0.7149 train_acc=0.0677 train_f1=0.0533 val_loss=0.5675 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 150/1000 | train_loss=0.6973 train_acc=0.0677 train_f1=0.0533 val_loss=0.5583 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 160/1000 | train_loss=0.6853 train_acc=0.0677 train_f1=0.0533 val_loss=0.5496 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 170/1000 | train_loss=0.6725 train_acc=0.0677 train_f1=0.0533 val_loss=0.5412 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 180/1000 | train_loss=0.6596 train_acc=0.0677 train_f1=0.0533 val_loss=0.5327 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 190/1000 | train_loss=0.6520 train_acc=0.0677 train_f1=0.0533 val_loss=0.5241 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 200/1000 | train_loss=0.6374 train_acc=0.0678 train_f1=0.0533 val_loss=0.5143 val_acc=0.0679 val_f1=0.0533 \n",
            "Epoch 210/1000 | train_loss=0.6269 train_acc=0.0734 train_f1=0.0551 val_loss=0.5032 val_acc=0.0735 val_f1=0.0551 \n",
            "Epoch 220/1000 | train_loss=0.6137 train_acc=0.1503 train_f1=0.0793 val_loss=0.4922 val_acc=0.1487 val_f1=0.0788 \n",
            "Epoch 230/1000 | train_loss=0.6072 train_acc=0.2230 train_f1=0.1018 val_loss=0.4813 val_acc=0.2213 val_f1=0.1013 \n",
            "Epoch 240/1000 | train_loss=0.5956 train_acc=0.2860 train_f1=0.1212 val_loss=0.4706 val_acc=0.2843 val_f1=0.1207 \n",
            "Epoch 250/1000 | train_loss=0.5810 train_acc=0.3800 train_f1=0.1501 val_loss=0.4598 val_acc=0.3770 val_f1=0.1492 \n",
            "Epoch 260/1000 | train_loss=0.5709 train_acc=0.4768 train_f1=0.1801 val_loss=0.4494 val_acc=0.4740 val_f1=0.1793 \n",
            "Epoch 270/1000 | train_loss=0.5636 train_acc=0.5625 train_f1=0.2076 val_loss=0.4389 val_acc=0.5596 val_f1=0.2067 \n",
            "Epoch 280/1000 | train_loss=0.5550 train_acc=0.6279 train_f1=0.2293 val_loss=0.4295 val_acc=0.6241 val_f1=0.2281 \n",
            "Epoch 290/1000 | train_loss=0.5451 train_acc=0.6871 train_f1=0.2502 val_loss=0.4197 val_acc=0.6847 val_f1=0.2494 \n",
            "Epoch 300/1000 | train_loss=0.5355 train_acc=0.7361 train_f1=0.2684 val_loss=0.4089 val_acc=0.7335 val_f1=0.2676 \n",
            "Epoch 310/1000 | train_loss=0.5276 train_acc=0.7690 train_f1=0.2814 val_loss=0.3993 val_acc=0.7669 val_f1=0.2807 \n",
            "Epoch 320/1000 | train_loss=0.5194 train_acc=0.7954 train_f1=0.2923 val_loss=0.3906 val_acc=0.7935 val_f1=0.2916 \n",
            "Epoch 330/1000 | train_loss=0.5114 train_acc=0.8153 train_f1=0.3009 val_loss=0.3830 val_acc=0.8141 val_f1=0.3005 \n",
            "Epoch 340/1000 | train_loss=0.5049 train_acc=0.8278 train_f1=0.3065 val_loss=0.3766 val_acc=0.8261 val_f1=0.3059 \n",
            "Epoch 350/1000 | train_loss=0.4995 train_acc=0.8461 train_f1=0.3150 val_loss=0.3693 val_acc=0.8445 val_f1=0.3143 \n",
            "Epoch 360/1000 | train_loss=0.4901 train_acc=0.8593 train_f1=0.3213 val_loss=0.3623 val_acc=0.8577 val_f1=0.3205 \n",
            "Epoch 370/1000 | train_loss=0.4821 train_acc=0.8708 train_f1=0.3269 val_loss=0.3551 val_acc=0.8694 val_f1=0.3263 \n",
            "Epoch 380/1000 | train_loss=0.4771 train_acc=0.8784 train_f1=0.3307 val_loss=0.3484 val_acc=0.8769 val_f1=0.3301 \n",
            "Epoch 390/1000 | train_loss=0.4708 train_acc=0.8840 train_f1=0.3336 val_loss=0.3427 val_acc=0.8824 val_f1=0.3329 \n",
            "Epoch 400/1000 | train_loss=0.4666 train_acc=0.8881 train_f1=0.3357 val_loss=0.3376 val_acc=0.8868 val_f1=0.3351 \n",
            "Epoch 410/1000 | train_loss=0.4634 train_acc=0.8905 train_f1=0.3370 val_loss=0.3333 val_acc=0.8893 val_f1=0.3364 \n",
            "Epoch 420/1000 | train_loss=0.4548 train_acc=0.8929 train_f1=0.3383 val_loss=0.3300 val_acc=0.8916 val_f1=0.3376 \n",
            "Epoch 430/1000 | train_loss=0.4583 train_acc=0.8954 train_f1=0.3396 val_loss=0.3265 val_acc=0.8941 val_f1=0.3390 \n",
            "Epoch 440/1000 | train_loss=0.4539 train_acc=0.8964 train_f1=0.3402 val_loss=0.3239 val_acc=0.8951 val_f1=0.3396 \n",
            "Epoch 450/1000 | train_loss=0.4482 train_acc=0.8979 train_f1=0.3410 val_loss=0.3215 val_acc=0.8967 val_f1=0.3404 \n",
            "Epoch 460/1000 | train_loss=0.4448 train_acc=0.8993 train_f1=0.3418 val_loss=0.3192 val_acc=0.8983 val_f1=0.3412 \n",
            "Epoch 470/1000 | train_loss=0.4459 train_acc=0.9004 train_f1=0.3424 val_loss=0.3170 val_acc=0.8995 val_f1=0.3419 \n",
            "Epoch 480/1000 | train_loss=0.4427 train_acc=0.9015 train_f1=0.3430 val_loss=0.3152 val_acc=0.9006 val_f1=0.3426 \n",
            "Epoch 490/1000 | train_loss=0.4422 train_acc=0.9026 train_f1=0.3436 val_loss=0.3135 val_acc=0.9017 val_f1=0.3432 \n",
            "Epoch 500/1000 | train_loss=0.4397 train_acc=0.9028 train_f1=0.3437 val_loss=0.3121 val_acc=0.9019 val_f1=0.3433 \n",
            "Epoch 510/1000 | train_loss=0.4350 train_acc=0.9044 train_f1=0.3446 val_loss=0.3105 val_acc=0.9035 val_f1=0.3442 \n",
            "Epoch 520/1000 | train_loss=0.4363 train_acc=0.9048 train_f1=0.3449 val_loss=0.3089 val_acc=0.9040 val_f1=0.3445 \n",
            "Epoch 530/1000 | train_loss=0.4340 train_acc=0.9052 train_f1=0.3451 val_loss=0.3076 val_acc=0.9044 val_f1=0.3447 \n",
            "Epoch 540/1000 | train_loss=0.4308 train_acc=0.9065 train_f1=0.3459 val_loss=0.3059 val_acc=0.9059 val_f1=0.3455 \n",
            "Epoch 550/1000 | train_loss=0.4302 train_acc=0.9065 train_f1=0.3459 val_loss=0.3046 val_acc=0.9057 val_f1=0.3454 \n",
            "Epoch 560/1000 | train_loss=0.4290 train_acc=0.9076 train_f1=0.3465 val_loss=0.3031 val_acc=0.9070 val_f1=0.3462 \n",
            "Epoch 570/1000 | train_loss=0.4282 train_acc=0.9081 train_f1=0.3468 val_loss=0.3019 val_acc=0.9074 val_f1=0.3464 \n",
            "Epoch 580/1000 | train_loss=0.4262 train_acc=0.9082 train_f1=0.3468 val_loss=0.3011 val_acc=0.9075 val_f1=0.3464 \n",
            "Epoch 590/1000 | train_loss=0.4238 train_acc=0.9088 train_f1=0.3472 val_loss=0.2998 val_acc=0.9082 val_f1=0.3469 \n",
            "Epoch 600/1000 | train_loss=0.4220 train_acc=0.9088 train_f1=0.3472 val_loss=0.2989 val_acc=0.9082 val_f1=0.3469 \n",
            "Epoch 610/1000 | train_loss=0.4202 train_acc=0.9099 train_f1=0.3478 val_loss=0.2980 val_acc=0.9092 val_f1=0.3474 \n",
            "Epoch 620/1000 | train_loss=0.4184 train_acc=0.9112 train_f1=0.3486 val_loss=0.2964 val_acc=0.9106 val_f1=0.3482 \n",
            "Epoch 630/1000 | train_loss=0.4174 train_acc=0.9109 train_f1=0.3484 val_loss=0.2951 val_acc=0.9102 val_f1=0.3480 \n",
            "Epoch 640/1000 | train_loss=0.4154 train_acc=0.9116 train_f1=0.3488 val_loss=0.2938 val_acc=0.9107 val_f1=0.3482 \n",
            "Epoch 650/1000 | train_loss=0.4125 train_acc=0.9122 train_f1=0.3491 val_loss=0.2928 val_acc=0.9113 val_f1=0.3486 \n",
            "Epoch 660/1000 | train_loss=0.4106 train_acc=0.9118 train_f1=0.3489 val_loss=0.2917 val_acc=0.9110 val_f1=0.3484 \n",
            "Epoch 670/1000 | train_loss=0.4134 train_acc=0.9131 train_f1=0.3497 val_loss=0.2906 val_acc=0.9121 val_f1=0.3491 \n",
            "Epoch 680/1000 | train_loss=0.4134 train_acc=0.9132 train_f1=0.3498 val_loss=0.2893 val_acc=0.9123 val_f1=0.3493 \n",
            "Epoch 690/1000 | train_loss=0.4110 train_acc=0.9133 train_f1=0.3498 val_loss=0.2883 val_acc=0.9125 val_f1=0.3493 \n",
            "Epoch 700/1000 | train_loss=0.4059 train_acc=0.9137 train_f1=0.3500 val_loss=0.2870 val_acc=0.9129 val_f1=0.3496 \n",
            "Epoch 710/1000 | train_loss=0.4046 train_acc=0.9151 train_f1=0.3509 val_loss=0.2855 val_acc=0.9142 val_f1=0.3503 \n",
            "Epoch 720/1000 | train_loss=0.4031 train_acc=0.9152 train_f1=0.3509 val_loss=0.2845 val_acc=0.9142 val_f1=0.3503 \n",
            "Epoch 730/1000 | train_loss=0.4017 train_acc=0.9156 train_f1=0.3511 val_loss=0.2832 val_acc=0.9147 val_f1=0.3506 \n",
            "Epoch 740/1000 | train_loss=0.4019 train_acc=0.9162 train_f1=0.3515 val_loss=0.2821 val_acc=0.9154 val_f1=0.3510 \n",
            "Epoch 750/1000 | train_loss=0.4007 train_acc=0.9169 train_f1=0.3519 val_loss=0.2807 val_acc=0.9161 val_f1=0.3515 \n",
            "Epoch 760/1000 | train_loss=0.4018 train_acc=0.9175 train_f1=0.3523 val_loss=0.2790 val_acc=0.9165 val_f1=0.3517 \n",
            "Epoch 770/1000 | train_loss=0.3947 train_acc=0.9180 train_f1=0.3525 val_loss=0.2779 val_acc=0.9169 val_f1=0.3519 \n",
            "Epoch 780/1000 | train_loss=0.3926 train_acc=0.9192 train_f1=0.3532 val_loss=0.2765 val_acc=0.9181 val_f1=0.3526 \n",
            "Epoch 790/1000 | train_loss=0.3963 train_acc=0.9192 train_f1=0.3532 val_loss=0.2751 val_acc=0.9180 val_f1=0.3525 \n",
            "Epoch 800/1000 | train_loss=0.3930 train_acc=0.9194 train_f1=0.3534 val_loss=0.2741 val_acc=0.9184 val_f1=0.3528 \n",
            "Epoch 810/1000 | train_loss=0.3919 train_acc=0.9208 train_f1=0.3542 val_loss=0.2727 val_acc=0.9196 val_f1=0.3535 \n",
            "Epoch 820/1000 | train_loss=0.3897 train_acc=0.9204 train_f1=0.3539 val_loss=0.2714 val_acc=0.9192 val_f1=0.3532 \n",
            "Epoch 830/1000 | train_loss=0.3896 train_acc=0.9214 train_f1=0.3545 val_loss=0.2700 val_acc=0.9202 val_f1=0.3538 \n",
            "Epoch 840/1000 | train_loss=0.3896 train_acc=0.9212 train_f1=0.3544 val_loss=0.2689 val_acc=0.9201 val_f1=0.3538 \n",
            "Epoch 850/1000 | train_loss=0.3866 train_acc=0.9218 train_f1=0.3548 val_loss=0.2680 val_acc=0.9207 val_f1=0.3542 \n",
            "Epoch 860/1000 | train_loss=0.3851 train_acc=0.9225 train_f1=0.3552 val_loss=0.2667 val_acc=0.9214 val_f1=0.3546 \n",
            "Epoch 870/1000 | train_loss=0.3830 train_acc=0.9223 train_f1=0.3551 val_loss=0.2659 val_acc=0.9211 val_f1=0.3543 \n",
            "Epoch 880/1000 | train_loss=0.3824 train_acc=0.9227 train_f1=0.3554 val_loss=0.2647 val_acc=0.9218 val_f1=0.3548 \n",
            "Epoch 890/1000 | train_loss=0.3798 train_acc=0.9219 train_f1=0.3549 val_loss=0.2639 val_acc=0.9208 val_f1=0.3542 \n",
            "Epoch 900/1000 | train_loss=0.3774 train_acc=0.9233 train_f1=0.3557 val_loss=0.2625 val_acc=0.9223 val_f1=0.3551 \n",
            "Epoch 910/1000 | train_loss=0.3776 train_acc=0.9232 train_f1=0.3556 val_loss=0.2616 val_acc=0.9220 val_f1=0.3549 \n",
            "Epoch 920/1000 | train_loss=0.3730 train_acc=0.9239 train_f1=0.3561 val_loss=0.2606 val_acc=0.9228 val_f1=0.3554 \n",
            "Epoch 930/1000 | train_loss=0.3734 train_acc=0.9237 train_f1=0.3559 val_loss=0.2597 val_acc=0.9225 val_f1=0.3552 \n",
            "Epoch 940/1000 | train_loss=0.3740 train_acc=0.9237 train_f1=0.3559 val_loss=0.2592 val_acc=0.9226 val_f1=0.3553 \n",
            "Epoch 950/1000 | train_loss=0.3723 train_acc=0.9238 train_f1=0.3560 val_loss=0.2583 val_acc=0.9227 val_f1=0.3554 \n",
            "Epoch 960/1000 | train_loss=0.3732 train_acc=0.9246 train_f1=0.3565 val_loss=0.2572 val_acc=0.9234 val_f1=0.3558 \n",
            "Epoch 970/1000 | train_loss=0.3695 train_acc=0.9240 train_f1=0.3561 val_loss=0.2569 val_acc=0.9228 val_f1=0.3553 \n",
            "Epoch 980/1000 | train_loss=0.3662 train_acc=0.9244 train_f1=0.3564 val_loss=0.2559 val_acc=0.9233 val_f1=0.3557 \n",
            "Epoch 990/1000 | train_loss=0.3703 train_acc=0.9242 train_f1=0.3563 val_loss=0.2553 val_acc=0.9232 val_f1=0.3556 \n",
            "Epoch 1000/1000 | train_loss=0.3687 train_acc=0.9248 train_f1=0.3567 val_loss=0.2544 val_acc=0.9237 val_f1=0.3560 \n"
          ]
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test output"
      ],
      "metadata": {
        "id": "WGchc6511C2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y_test = prepare_data(test_dataset, device)\n",
        "\n",
        "# Get predictions\n",
        "with torch.no_grad():\n",
        "    logits = model(X_test)\n",
        "    probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "    predictions = probs.argmax(axis=1)\n",
        "\n",
        "y_true = y_test.cpu().numpy()\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_true, predictions)\n",
        "f_beta = fbeta_score(y_true, predictions, average=\"macro\", beta=2)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test F-Beta (macro): {f_beta:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "wcGqY8qX1C2R"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}