{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 117287,
          "databundleVersionId": 14018857,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31153,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "nathaniel14133437_midterm_CS5173",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grillinr/evolutionary-computing/blob/main/final/final_proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and seed for easier checking"
      ],
      "metadata": {
        "id": "uibqKYOH1C2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0.66 is baseline for score\n",
        "import random\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.metrics import accuracy_score, fbeta_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "SEED = 5173\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:35:17.559153Z",
          "iopub.execute_input": "2025-10-17T00:35:17.559461Z",
          "iopub.status.idle": "2025-10-17T00:35:17.568112Z",
          "shell.execute_reply.started": "2025-10-17T00:35:17.559437Z",
          "shell.execute_reply": "2025-10-17T00:35:17.567065Z"
        },
        "id": "rU8AhTMY1C2N"
      },
      "outputs": [],
      "execution_count": 50
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define helper functions"
      ],
      "metadata": {
        "id": "i8xd5F721C2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(data, device):\n",
        "    # Drop non-numeric and class columns\n",
        "    data = data.dropna()\n",
        "    X = data.drop(columns=[\"id\", \"record\", \"type\"]).values.astype(np.float32)\n",
        "\n",
        "    # Convert class to numeric value from 0-4\n",
        "    y = data[\"type\"].astype(\"category\").cat.codes.values\n",
        "\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.long).to(device)\n",
        "\n",
        "    return X_tensor, y_tensor\n",
        "\n",
        "\n",
        "def evaluate(model, device, data, criterion):\n",
        "    model.eval()\n",
        "\n",
        "    X, y = prepare_data(data, device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(X)\n",
        "        loss = criterion(logits, y)\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "    y_true = y.cpu().numpy()\n",
        "    y_pred = probs.argmax(axis=1)\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f_beta_m = fbeta_score(y_true, y_pred, average=\"macro\", beta=2)\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss.item(),\n",
        "        \"accuracy\": acc,\n",
        "        \"f_beta_macro\": f_beta_m,\n",
        "    }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:46:03.730208Z",
          "iopub.execute_input": "2025-10-17T00:46:03.730536Z",
          "iopub.status.idle": "2025-10-17T00:46:03.738421Z",
          "shell.execute_reply.started": "2025-10-17T00:46:03.730511Z",
          "shell.execute_reply": "2025-10-17T00:46:03.73737Z"
        },
        "id": "ZxxTIRWL1C2O"
      },
      "outputs": [],
      "execution_count": 59
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Model Architecture (DNN)"
      ],
      "metadata": {
        "id": "dTi3Q6241C2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNN(nn.Module):\n",
        "    def __init__(self, input_size=32, hidden=(32, 16, 8), num_classes=5, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        input_dim = input_size\n",
        "\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "            layers.append(nn.Dropout(dropout_rate))\n",
        "            input_dim = h\n",
        "\n",
        "        layers.append(nn.Linear(input_dim, num_classes))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:35:38.736024Z",
          "iopub.execute_input": "2025-10-17T00:35:38.736378Z",
          "iopub.status.idle": "2025-10-17T00:35:38.74276Z",
          "shell.execute_reply.started": "2025-10-17T00:35:38.736352Z",
          "shell.execute_reply": "2025-10-17T00:35:38.741836Z"
        },
        "id": "qzOM0laS1C2P"
      },
      "outputs": [],
      "execution_count": 52
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Training loop"
      ],
      "metadata": {
        "id": "8V1SVoBd1C2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "dataset = pd.read_csv(\"/content/train.csv\")\n",
        "train_dataset, test_dataset = train_test_split(dataset, train_size=0.7, random_state=SEED)\n",
        "# test_dataset = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:46:12.869203Z",
          "iopub.execute_input": "2025-10-17T00:46:12.869487Z",
          "iopub.status.idle": "2025-10-17T00:46:18.983013Z",
          "shell.execute_reply.started": "2025-10-17T00:46:12.869467Z",
          "shell.execute_reply": "2025-10-17T00:46:18.982193Z"
        },
        "id": "Dv6o3n1t1C2Q"
      },
      "outputs": [],
      "execution_count": 60
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "hidden = (32, 16, 8)\n",
        "dropout_rate = 0.5\n",
        "patience = 10\n",
        "\n",
        "# Create model\n",
        "model = DNN(hidden=hidden, dropout_rate=dropout_rate).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:35:56.034543Z",
          "iopub.execute_input": "2025-10-17T00:35:56.034924Z",
          "iopub.status.idle": "2025-10-17T00:35:56.042659Z",
          "shell.execute_reply.started": "2025-10-17T00:35:56.034863Z",
          "shell.execute_reply": "2025-10-17T00:35:56.041417Z"
        },
        "id": "R3uFXDIH1C2Q"
      },
      "outputs": [],
      "execution_count": 63
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare tensors\n",
        "X_train, y_train = prepare_data(train_dataset, device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:46:27.434167Z",
          "iopub.execute_input": "2025-10-17T00:46:27.434468Z",
          "iopub.status.idle": "2025-10-17T00:46:27.608016Z",
          "shell.execute_reply.started": "2025-10-17T00:46:27.434445Z",
          "shell.execute_reply": "2025-10-17T00:46:27.606679Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juZ8bqN81C2R",
        "outputId": "f9016579-e158-49e0-fe8f-eafb8c04b418"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "execution_count": 61
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with early stopping\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(X_train)\n",
        "    loss = criterion(out, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss = loss.item()\n",
        "\n",
        "    train_metrics = evaluate(model, device, train_dataset, criterion)\n",
        "    val_metrics = evaluate(model, device, test_dataset, criterion)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch}/{epochs} | \"\n",
        "        f\"train_loss={train_loss:.4f} train_acc={train_metrics['accuracy']:.4f} \"\n",
        "        f\"train_f1={train_metrics['f_beta_macro']:.4f} | \"\n",
        "        f\"val_loss={val_metrics['loss']:.4f} val_acc={val_metrics['accuracy']:.4f} \"\n",
        "        f\"val_f1={val_metrics['f_beta_macro']:.4f}\"\n",
        "    )\n",
        "\n",
        "    # Early stopping check\n",
        "    if val_metrics['loss'] < best_val_loss:\n",
        "        best_val_loss = val_metrics['loss']\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:43:03.337535Z",
          "iopub.execute_input": "2025-10-17T00:43:03.337852Z",
          "iopub.status.idle": "2025-10-17T00:43:03.676338Z",
          "shell.execute_reply.started": "2025-10-17T00:43:03.337828Z",
          "shell.execute_reply": "2025-10-17T00:43:03.675024Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "id": "pEO7m2r11C2R",
        "outputId": "0a66c143-cb3a-4432-ff58-d1ed2ad2b8ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 | train_loss=4.3106 train_acc=0.8344 train_f1=0.2437 | val_loss=1.2239 val_acc=0.8346 val_f1=0.2431\n",
            "Epoch 2/100 | train_loss=3.9643 train_acc=0.8801 train_f1=0.2308 | val_loss=1.1346 val_acc=0.8795 val_f1=0.2309\n",
            "Epoch 3/100 | train_loss=3.6687 train_acc=0.8988 train_f1=0.2116 | val_loss=1.0714 val_acc=0.8989 val_f1=0.2147\n",
            "Epoch 4/100 | train_loss=3.3967 train_acc=0.9041 train_f1=0.2097 | val_loss=1.0262 val_acc=0.9042 val_f1=0.2129\n",
            "Epoch 5/100 | train_loss=3.1573 train_acc=0.9048 train_f1=0.2036 | val_loss=0.9902 val_acc=0.9046 val_f1=0.2076\n",
            "Epoch 6/100 | train_loss=2.9443 train_acc=0.9050 train_f1=0.2014 | val_loss=0.9597 val_acc=0.9047 val_f1=0.1991\n",
            "Epoch 7/100 | train_loss=2.7721 train_acc=0.9049 train_f1=0.2007 | val_loss=0.9326 val_acc=0.9046 val_f1=0.1981\n",
            "Epoch 8/100 | train_loss=2.6036 train_acc=0.9048 train_f1=0.2002 | val_loss=0.9075 val_acc=0.9047 val_f1=0.1977\n",
            "Epoch 9/100 | train_loss=2.4583 train_acc=0.9048 train_f1=0.1971 | val_loss=0.8852 val_acc=0.9046 val_f1=0.1973\n",
            "Epoch 10/100 | train_loss=2.3415 train_acc=0.9047 train_f1=0.1968 | val_loss=0.8654 val_acc=0.9045 val_f1=0.1970\n",
            "Epoch 11/100 | train_loss=2.2176 train_acc=0.9047 train_f1=0.1966 | val_loss=0.8476 val_acc=0.9045 val_f1=0.1969\n",
            "Epoch 12/100 | train_loss=2.1308 train_acc=0.9046 train_f1=0.1965 | val_loss=0.8316 val_acc=0.9044 val_f1=0.1967\n",
            "Epoch 13/100 | train_loss=2.0545 train_acc=0.9046 train_f1=0.1964 | val_loss=0.8167 val_acc=0.9044 val_f1=0.1965\n",
            "Epoch 14/100 | train_loss=1.9772 train_acc=0.9046 train_f1=0.1962 | val_loss=0.8024 val_acc=0.9043 val_f1=0.1963\n",
            "Epoch 15/100 | train_loss=1.9069 train_acc=0.9045 train_f1=0.1961 | val_loss=0.7887 val_acc=0.9043 val_f1=0.1962\n",
            "Epoch 16/100 | train_loss=1.8526 train_acc=0.9045 train_f1=0.1960 | val_loss=0.7759 val_acc=0.9043 val_f1=0.1961\n",
            "Epoch 17/100 | train_loss=1.7951 train_acc=0.9045 train_f1=0.1960 | val_loss=0.7643 val_acc=0.9043 val_f1=0.1960\n",
            "Epoch 18/100 | train_loss=1.7383 train_acc=0.9045 train_f1=0.1960 | val_loss=0.7535 val_acc=0.9042 val_f1=0.1960\n",
            "Epoch 19/100 | train_loss=1.6949 train_acc=0.9045 train_f1=0.1959 | val_loss=0.7433 val_acc=0.9042 val_f1=0.1960\n",
            "Epoch 20/100 | train_loss=1.6559 train_acc=0.9045 train_f1=0.1959 | val_loss=0.7339 val_acc=0.9042 val_f1=0.1959\n",
            "Epoch 21/100 | train_loss=1.6234 train_acc=0.9045 train_f1=0.1959 | val_loss=0.7251 val_acc=0.9042 val_f1=0.1959\n",
            "Epoch 22/100 | train_loss=1.5832 train_acc=0.9045 train_f1=0.1959 | val_loss=0.7170 val_acc=0.9042 val_f1=0.1959\n",
            "Epoch 23/100 | train_loss=1.5489 train_acc=0.9045 train_f1=0.1959 | val_loss=0.7097 val_acc=0.9042 val_f1=0.1959\n",
            "Epoch 24/100 | train_loss=1.5231 train_acc=0.9045 train_f1=0.1959 | val_loss=0.7031 val_acc=0.9042 val_f1=0.1959\n",
            "Epoch 25/100 | train_loss=1.4962 train_acc=0.9045 train_f1=0.1959 | val_loss=0.6972 val_acc=0.9042 val_f1=0.1959\n",
            "Epoch 26/100 | train_loss=1.4701 train_acc=0.9045 train_f1=0.1959 | val_loss=0.6920 val_acc=0.9042 val_f1=0.1959\n",
            "Epoch 27/100 | train_loss=1.4462 train_acc=0.9045 train_f1=0.1959 | val_loss=0.6874 val_acc=0.9042 val_f1=0.1959\n",
            "Epoch 28/100 | train_loss=1.4234 train_acc=0.9045 train_f1=0.1959 | val_loss=0.6833 val_acc=0.9042 val_f1=0.1959\n",
            "Epoch 29/100 | train_loss=1.4018 train_acc=0.9045 train_f1=0.1959 | val_loss=0.6797 val_acc=0.9042 val_f1=0.1959\n",
            "Epoch 30/100 | train_loss=1.3800 train_acc=0.9045 train_f1=0.1959 | val_loss=0.6766 val_acc=0.9042 val_f1=0.1959\n",
            "Epoch 31/100 | train_loss=1.3622 train_acc=0.9045 train_f1=0.1959 | val_loss=0.6738 val_acc=0.9042 val_f1=0.1959\n",
            "Epoch 32/100 | train_loss=1.3499 train_acc=0.9045 train_f1=0.1959 | val_loss=0.6714 val_acc=0.9042 val_f1=0.1959\n",
            "Epoch 33/100 | train_loss=1.3302 train_acc=0.9045 train_f1=0.1959 | val_loss=0.6693 val_acc=0.9042 val_f1=0.1959\n",
            "Epoch 34/100 | train_loss=1.3114 train_acc=0.9045 train_f1=0.1959 | val_loss=0.6676 val_acc=0.9042 val_f1=0.1959\n",
            "Epoch 35/100 | train_loss=1.3048 train_acc=0.9045 train_f1=0.1959 | val_loss=0.6662 val_acc=0.9042 val_f1=0.1959\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-984270264.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 65
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test output on split data to avoid submitting"
      ],
      "metadata": {
        "id": "WGchc6511C2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y_test = prepare_data(test_dataset, device)\n",
        "\n",
        "# Get predictions\n",
        "with torch.no_grad():\n",
        "    logits = model(X_test)\n",
        "    probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "    predictions = probs.argmax(axis=1)\n",
        "\n",
        "y_true = y_test.cpu().numpy()\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_true, predictions)\n",
        "f_beta = fbeta_score(y_true, predictions, average=\"macro\", beta=2)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test F-Beta (macro): {f_beta:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "wcGqY8qX1C2R"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}