{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 117287,
          "databundleVersionId": 14018857,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31153,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "nathaniel14133437_midterm_CS5173",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grillinr/evolutionary-computing/blob/main/final/final_proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and seed for easier checking"
      ],
      "metadata": {
        "id": "uibqKYOH1C2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "import argparse\n",
        "import math\n",
        "from typing import List, Tuple\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.metrics import accuracy_score, fbeta_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "SEED = 5173\n",
        "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda\")\n",
        "print(device)\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:35:17.559153Z",
          "iopub.execute_input": "2025-10-17T00:35:17.559461Z",
          "iopub.status.idle": "2025-10-17T00:35:17.568112Z",
          "shell.execute_reply.started": "2025-10-17T00:35:17.559437Z",
          "shell.execute_reply": "2025-10-17T00:35:17.567065Z"
        },
        "id": "rU8AhTMY1C2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49507d34-4af5-4f8d-c4b6-efc2274ec81a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "execution_count": 71
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define helper functions"
      ],
      "metadata": {
        "id": "i8xd5F721C2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_with_scaler(data, scaler=None, fit=False):\n",
        "    data = data.dropna()\n",
        "    X = data.drop(columns=[\"id\", \"record\", \"type\"]).values.astype(np.float32)\n",
        "    y = data[\"type\"].astype(\"category\").cat.codes.values\n",
        "\n",
        "    if fit:\n",
        "        X = scaler.fit_transform(X)\n",
        "    else:\n",
        "        X = scaler.transform(X)\n",
        "\n",
        "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "\n",
        "def evaluate(model, X, y, criterion):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(X)\n",
        "        loss = criterion(logits, y)\n",
        "        y_pred = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "    y_true = y.cpu().numpy()\n",
        "    return {\n",
        "        \"loss\": loss.item(),\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"f_beta_macro\": fbeta_score(y_true, y_pred, average=\"macro\", beta=2, zero_division=0)\n",
        "    }\n",
        "\n",
        "\n",
        "def estimate_flops(model, input_shape):\n",
        "    \"\"\"\n",
        "    Estimate FLOPs for Linear and Conv2d layers only.\n",
        "    Args:\n",
        "        model (nn.Module): PyTorch model\n",
        "        input_shape (tuple): shape of one input sample, e.g., (1, 3, 224, 224) or (1, input_dim)\n",
        "    Returns:\n",
        "        total_flops (int)\n",
        "    \"\"\"\n",
        "    flops = 0\n",
        "\n",
        "    def count_layer(layer, x_in, x_out):\n",
        "        nonlocal flops\n",
        "        # Conv2d FLOPs = Kx * Ky * Cin * Cout * Hout * Wout\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            out_h, out_w = x_out.shape[2:]\n",
        "            kernel_ops = layer.kernel_size[0] * layer.kernel_size[1]\n",
        "            flops += kernel_ops * layer.in_channels * layer.out_channels * out_h * out_w\n",
        "        # Linear FLOPs = input_features * output_features\n",
        "        elif isinstance(layer, nn.Linear):\n",
        "            flops += layer.in_features * layer.out_features\n",
        "\n",
        "    hooks = []\n",
        "    for layer in model.modules():\n",
        "        if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
        "            hooks.append(layer.register_forward_hook(count_layer))\n",
        "\n",
        "    dummy = torch.randn(input_shape).to(next(model.parameters()).device)\n",
        "    with torch.no_grad():\n",
        "        model(dummy)\n",
        "\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "\n",
        "    return flops"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:46:03.730208Z",
          "iopub.execute_input": "2025-10-17T00:46:03.730536Z",
          "iopub.status.idle": "2025-10-17T00:46:03.738421Z",
          "shell.execute_reply.started": "2025-10-17T00:46:03.730511Z",
          "shell.execute_reply": "2025-10-17T00:46:03.73737Z"
        },
        "id": "ZxxTIRWL1C2O"
      },
      "outputs": [],
      "execution_count": 44
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Model Architecture (DNN)"
      ],
      "metadata": {
        "id": "dTi3Q6241C2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNN(nn.Module):\n",
        "    def __init__(self, input_size=32, hidden=(32, 16, 8), num_classes=5, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        input_dim = input_size\n",
        "\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "            layers.append(nn.Dropout(dropout_rate))\n",
        "            input_dim = h\n",
        "\n",
        "        layers.append(nn.Linear(input_dim, num_classes))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:35:38.736024Z",
          "iopub.execute_input": "2025-10-17T00:35:38.736378Z",
          "iopub.status.idle": "2025-10-17T00:35:38.74276Z",
          "shell.execute_reply.started": "2025-10-17T00:35:38.736352Z",
          "shell.execute_reply": "2025-10-17T00:35:38.741836Z"
        },
        "id": "qzOM0laS1C2P"
      },
      "outputs": [],
      "execution_count": 46
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Training loop"
      ],
      "metadata": {
        "id": "8V1SVoBd1C2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "dataset = pd.read_csv(\"/content/train.csv\")\n",
        "train_dataset, val_dataset = train_test_split(dataset, train_size=0.7, random_state=SEED)\n",
        "scaler = StandardScaler()\n",
        "X_train, y_train = prepare_data_with_scaler(train_dataset, scaler, fit=True)\n",
        "X_val, y_val = prepare_data_with_scaler(val_dataset, scaler, fit=False)\n",
        "\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "X_val, y_val = X_val.to(device), y_val.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:46:12.869203Z",
          "iopub.execute_input": "2025-10-17T00:46:12.869487Z",
          "iopub.status.idle": "2025-10-17T00:46:18.983013Z",
          "shell.execute_reply.started": "2025-10-17T00:46:12.869467Z",
          "shell.execute_reply": "2025-10-17T00:46:18.982193Z"
        },
        "id": "Dv6o3n1t1C2Q"
      },
      "outputs": [],
      "execution_count": 47
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "class Hyperparameters:\n",
        "    def __init__(self, lr, epochs, hidden, dropout_rate, patience):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.hidden = hidden\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.patience = patience"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:35:56.034543Z",
          "iopub.execute_input": "2025-10-17T00:35:56.034924Z",
          "iopub.status.idle": "2025-10-17T00:35:56.042659Z",
          "shell.execute_reply.started": "2025-10-17T00:35:56.034863Z",
          "shell.execute_reply": "2025-10-17T00:35:56.041417Z"
        },
        "id": "R3uFXDIH1C2Q"
      },
      "outputs": [],
      "execution_count": 58
    },
    {
      "cell_type": "code",
      "source": [
        "def train(params: Hyperparameters):\n",
        "  # Create model\n",
        "  model = DNN(hidden=params.hidden, dropout_rate=params.dropout_rate).to(device)\n",
        "\n",
        "  class_counts = train_dataset['type'].value_counts()\n",
        "  weights = 1.0 / class_counts.values\n",
        "  weights = torch.FloatTensor(weights).to(device)\n",
        "  criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=params.lr)\n",
        "\n",
        "  # Training loop with early stopping\n",
        "  best_val_loss = float('inf')\n",
        "  patience_counter = 0\n",
        "  epochs_run = params.epochs\n",
        "  for epoch in range(1, params.epochs + 1):\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "      out = model(X_train)\n",
        "      loss = criterion(out, y_train)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss = loss.item()\n",
        "\n",
        "      train_metrics = evaluate(model, X_train, y_train, criterion)\n",
        "      val_metrics = evaluate(model, X_val, y_val, criterion)\n",
        "\n",
        "      if epoch % (params.epochs // 10) == 0:\n",
        "        print(\n",
        "            f\"Epoch {epoch}/{params.epochs} | \"\n",
        "            f\"train_loss={train_loss:.4f} train_acc={train_metrics['accuracy']:.4f} \"\n",
        "            f\"train_f1={train_metrics['f_beta_macro']:.4f} \"\n",
        "            f\"val_loss={val_metrics['loss']:.4f} val_acc={val_metrics['accuracy']:.4f} \"\n",
        "            f\"val_f1={val_metrics['f_beta_macro']:.4f} \"\n",
        "        )\n",
        "\n",
        "      # Early stopping check\n",
        "      if val_metrics['loss'] < best_val_loss:\n",
        "          best_val_loss = val_metrics['loss']\n",
        "          patience_counter = 0\n",
        "      else:\n",
        "          patience_counter += 1\n",
        "          if patience_counter >= params.patience:\n",
        "              print(f\"Early stopping at epoch {epoch}\")\n",
        "              epochs_run = epoch\n",
        "              break\n",
        "\n",
        "  results = {\"epochs_run\": epochs_run,\n",
        "            \"val_loss\": val_metrics[\"loss\"],\n",
        "            \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "            \"val_f1\": val_metrics[\"f_beta_macro\"],\n",
        "            \"flops\": estimate_flops(model, (1, 32))\n",
        "            }\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:43:03.337535Z",
          "iopub.execute_input": "2025-10-17T00:43:03.337852Z",
          "iopub.status.idle": "2025-10-17T00:43:03.676338Z",
          "shell.execute_reply.started": "2025-10-17T00:43:03.337828Z",
          "shell.execute_reply": "2025-10-17T00:43:03.675024Z"
        },
        "id": "pEO7m2r11C2R"
      },
      "outputs": [],
      "execution_count": 63
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the function\n",
        "hyperparameters = Hyperparameters(lr=1e-3, epochs=500, hidden=(64, 32, 16, 8), dropout_rate=0.5, patience=100)\n",
        "result = train(hyperparameters)"
      ],
      "metadata": {
        "id": "fUhJqaHLMxKK",
        "outputId": "2d33fdfe-c5b8-4b84-ddc7-d8e410373fe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/500 | train_loss=1.0105 train_acc=0.0677 train_f1=0.0533 val_loss=0.6583 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 100/500 | train_loss=0.7896 train_acc=0.4054 train_f1=0.1579 val_loss=0.5629 val_acc=0.4034 val_f1=0.1574 \n",
            "Epoch 150/500 | train_loss=0.6818 train_acc=0.6302 train_f1=0.2302 val_loss=0.4893 val_acc=0.6285 val_f1=0.2298 \n",
            "Epoch 200/500 | train_loss=0.6099 train_acc=0.7641 train_f1=0.2799 val_loss=0.4391 val_acc=0.7640 val_f1=0.2800 \n",
            "Epoch 250/500 | train_loss=0.5695 train_acc=0.8497 train_f1=0.3178 val_loss=0.4081 val_acc=0.8482 val_f1=0.3171 \n",
            "Epoch 300/500 | train_loss=0.5248 train_acc=0.9132 train_f1=0.3509 val_loss=0.3724 val_acc=0.9118 val_f1=0.3500 \n",
            "Epoch 350/500 | train_loss=0.4618 train_acc=0.9339 train_f1=0.3633 val_loss=0.3033 val_acc=0.9324 val_f1=0.3622 \n",
            "Epoch 400/500 | train_loss=0.4270 train_acc=0.9327 train_f1=0.3628 val_loss=0.2702 val_acc=0.9315 val_f1=0.3618 \n",
            "Epoch 450/500 | train_loss=0.4008 train_acc=0.9336 train_f1=0.3632 val_loss=0.2523 val_acc=0.9324 val_f1=0.3623 \n",
            "Epoch 500/500 | train_loss=0.3863 train_acc=0.9340 train_f1=0.3637 val_loss=0.2375 val_acc=0.9328 val_f1=0.3629 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "id": "jiHb73eGRDqO",
        "outputId": "5a1b9fea-cbbe-43f7-81d8-b10b722463f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epochs_run': 500, 'val_loss': 0.20437687635421753, 'val_accuracy': 0.9285204469665945, 'val_f1': 0.35985153089835187, 'flops': 4776}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neuroevolution"
      ],
      "metadata": {
        "id": "3_uGubzQTmqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_population(pop_size: int, mem_size: int, mem_range: Tuple[float, float], sigma: float, rng: random.Random) -> List[List[float]]:\n",
        "    population = []\n",
        "    for _ in range(pop_size):\n",
        "        member = []\n",
        "        for _ in range(mem_size):\n",
        "            gene = rng.uniform(mem_range[0], mem_range[1])\n",
        "            member.append(gene)\n",
        "        member.append(sigma)\n",
        "        population.append(member)\n",
        "    return population\n",
        "\n",
        "def evolution_strategy(fitness_fn, mu: int, lambda_: int, mem_size: int, mem_range: Tuple[float, float], sigma: float, tau: float, max_gens: int, rng: random.Random) -> List[List[float]]:\n",
        "    population = init_population(mu, mem_size, mem_range, sigma, rng)\n",
        "    cumulative_evals = 0\n",
        "\n",
        "    for generation_number in range(1, max_gens + 1):\n",
        "        fitnesses = [fitness_fn.fitness(member[:mem_size]) for member in population]\n",
        "        cumulative_evals += mu\n",
        "\n",
        "        offspring = []\n",
        "        for _ in range(lambda_):\n",
        "            # Select parent using tournament\n",
        "            candidates = rng.sample(range(mu), 2)\n",
        "            parent_idx = max(candidates, key=lambda i: fitnesses[i])\n",
        "            parent = population[parent_idx]\n",
        "\n",
        "            child = []\n",
        "            genes = parent[:mem_size]\n",
        "            sigma_val = parent[mem_size]\n",
        "            for gene in genes:\n",
        "                mutation = rng.gauss(0.0, sigma_val)\n",
        "                mutated_gene = gene + mutation\n",
        "                child.append(mutated_gene)\n",
        "            # Mutate sigma\n",
        "            sigma_mutation = rng.gauss(0.0, 1.0)\n",
        "            new_sigma = sigma_val * math.exp(tau * sigma_mutation)\n",
        "            child.append(new_sigma)\n",
        "            offspring.append(child)\n",
        "\n",
        "        offspring_fitnesses = [fitness_fn.fitness(member[:mem_size]) for member in offspring]\n",
        "        cumulative_evals += lambda_\n",
        "\n",
        "        max_fitness = max(fitnesses)\n",
        "        average = sum(fitnesses) / mu\n",
        "        diversity = 0.0\n",
        "        for i in range(mu):\n",
        "            for j in range(i + 1, mu):\n",
        "                dist = math.sqrt(sum((population[i][k] - population[j][k])**2 for k in range(mem_size)))\n",
        "                if dist > diversity:\n",
        "                    diversity = dist\n",
        "        print(f\"Himmelblau ES {mu} {lambda_} {tau} 0.0 {generation_number} {cumulative_evals} {max_fitness} {average} {diversity}\")\n",
        "\n",
        "        if average > 0.99:\n",
        "            break\n",
        "\n",
        "        # Select best mu from offspring\n",
        "        indexed = [(f, i) for i, f in enumerate(offspring_fitnesses)]\n",
        "        indexed.sort(key=lambda x: x[0], reverse=True)\n",
        "        selected_indices = [i for _, i in indexed[:mu]]\n",
        "\n",
        "        new_population = [offspring[idx] for idx in selected_indices]\n",
        "        population = new_population\n",
        "\n",
        "    return population\n"
      ],
      "metadata": {
        "id": "-_jNJVH6TmSq"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test output"
      ],
      "metadata": {
        "id": "WGchc6511C2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y_test = prepare_data(test_dataset, device)\n",
        "\n",
        "# Get predictions\n",
        "with torch.no_grad():\n",
        "    logits = model(X_test)\n",
        "    probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "    predictions = probs.argmax(axis=1)\n",
        "\n",
        "y_true = y_test.cpu().numpy()\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_true, predictions)\n",
        "f_beta = fbeta_score(y_true, predictions, average=\"macro\", beta=2)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test F-Beta (macro): {f_beta:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "wcGqY8qX1C2R"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}