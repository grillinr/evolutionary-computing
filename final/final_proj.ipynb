{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 117287,
          "databundleVersionId": 14018857,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31153,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "nathaniel14133437_midterm_CS5173",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grillinr/evolutionary-computing/blob/main/final/final_proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and seed for easier checking"
      ],
      "metadata": {
        "id": "uibqKYOH1C2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "import argparse\n",
        "import math\n",
        "from typing import List, Tuple\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.metrics import accuracy_score, fbeta_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "SEED = 5173\n",
        "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda\")\n",
        "print(device)\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:35:17.559153Z",
          "iopub.execute_input": "2025-10-17T00:35:17.559461Z",
          "iopub.status.idle": "2025-10-17T00:35:17.568112Z",
          "shell.execute_reply.started": "2025-10-17T00:35:17.559437Z",
          "shell.execute_reply": "2025-10-17T00:35:17.567065Z"
        },
        "id": "rU8AhTMY1C2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49507d34-4af5-4f8d-c4b6-efc2274ec81a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "execution_count": 71
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define helper functions"
      ],
      "metadata": {
        "id": "i8xd5F721C2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_with_scaler(data, scaler=None, fit=False):\n",
        "    data = data.dropna()\n",
        "    X = data.drop(columns=[\"id\", \"record\", \"type\"]).values.astype(np.float32)\n",
        "    y = data[\"type\"].astype(\"category\").cat.codes.values\n",
        "\n",
        "    if fit:\n",
        "        X = scaler.fit_transform(X)\n",
        "    else:\n",
        "        X = scaler.transform(X)\n",
        "\n",
        "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "\n",
        "def evaluate(model, X, y, criterion):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(X)\n",
        "        loss = criterion(logits, y)\n",
        "        y_pred = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "    y_true = y.cpu().numpy()\n",
        "    return {\n",
        "        \"loss\": loss.item(),\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"f_beta_macro\": fbeta_score(y_true, y_pred, average=\"macro\", beta=2, zero_division=0)\n",
        "    }\n",
        "\n",
        "\n",
        "def estimate_flops(model, input_shape):\n",
        "    \"\"\"\n",
        "    Estimate FLOPs for Linear and Conv2d layers only.\n",
        "    Args:\n",
        "        model (nn.Module): PyTorch model\n",
        "        input_shape (tuple): shape of one input sample, e.g., (1, 3, 224, 224) or (1, input_dim)\n",
        "    Returns:\n",
        "        total_flops (int)\n",
        "    \"\"\"\n",
        "    flops = 0\n",
        "\n",
        "    def count_layer(layer, x_in, x_out):\n",
        "        nonlocal flops\n",
        "        # Conv2d FLOPs = Kx * Ky * Cin * Cout * Hout * Wout\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            out_h, out_w = x_out.shape[2:]\n",
        "            kernel_ops = layer.kernel_size[0] * layer.kernel_size[1]\n",
        "            flops += kernel_ops * layer.in_channels * layer.out_channels * out_h * out_w\n",
        "        # Linear FLOPs = input_features * output_features\n",
        "        elif isinstance(layer, nn.Linear):\n",
        "            flops += layer.in_features * layer.out_features\n",
        "\n",
        "    hooks = []\n",
        "    for layer in model.modules():\n",
        "        if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
        "            hooks.append(layer.register_forward_hook(count_layer))\n",
        "\n",
        "    dummy = torch.randn(input_shape).to(next(model.parameters()).device)\n",
        "    with torch.no_grad():\n",
        "        model(dummy)\n",
        "\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "\n",
        "    return flops"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:46:03.730208Z",
          "iopub.execute_input": "2025-10-17T00:46:03.730536Z",
          "iopub.status.idle": "2025-10-17T00:46:03.738421Z",
          "shell.execute_reply.started": "2025-10-17T00:46:03.730511Z",
          "shell.execute_reply": "2025-10-17T00:46:03.73737Z"
        },
        "id": "ZxxTIRWL1C2O"
      },
      "outputs": [],
      "execution_count": 44
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Model Architecture (DNN)"
      ],
      "metadata": {
        "id": "dTi3Q6241C2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNN(nn.Module):\n",
        "    def __init__(self, input_size=32, hidden=(32, 16, 8), num_classes=5, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        input_dim = input_size\n",
        "\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "            layers.append(nn.Dropout(dropout_rate))\n",
        "            input_dim = h\n",
        "\n",
        "        layers.append(nn.Linear(input_dim, num_classes))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:35:38.736024Z",
          "iopub.execute_input": "2025-10-17T00:35:38.736378Z",
          "iopub.status.idle": "2025-10-17T00:35:38.74276Z",
          "shell.execute_reply.started": "2025-10-17T00:35:38.736352Z",
          "shell.execute_reply": "2025-10-17T00:35:38.741836Z"
        },
        "id": "qzOM0laS1C2P"
      },
      "outputs": [],
      "execution_count": 46
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Training loop"
      ],
      "metadata": {
        "id": "8V1SVoBd1C2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "dataset = pd.read_csv(\"/content/train.csv\")\n",
        "train_dataset, val_dataset = train_test_split(dataset, train_size=0.7, random_state=SEED)\n",
        "scaler = StandardScaler()\n",
        "X_train, y_train = prepare_data_with_scaler(train_dataset, scaler, fit=True)\n",
        "X_val, y_val = prepare_data_with_scaler(val_dataset, scaler, fit=False)\n",
        "\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "X_val, y_val = X_val.to(device), y_val.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:46:12.869203Z",
          "iopub.execute_input": "2025-10-17T00:46:12.869487Z",
          "iopub.status.idle": "2025-10-17T00:46:18.983013Z",
          "shell.execute_reply.started": "2025-10-17T00:46:12.869467Z",
          "shell.execute_reply": "2025-10-17T00:46:18.982193Z"
        },
        "id": "Dv6o3n1t1C2Q"
      },
      "outputs": [],
      "execution_count": 47
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "class Hyperparameters:\n",
        "    def __init__(self, lr, epochs, hidden, dropout_rate, patience):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.hidden = hidden\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.patience = patience"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:35:56.034543Z",
          "iopub.execute_input": "2025-10-17T00:35:56.034924Z",
          "iopub.status.idle": "2025-10-17T00:35:56.042659Z",
          "shell.execute_reply.started": "2025-10-17T00:35:56.034863Z",
          "shell.execute_reply": "2025-10-17T00:35:56.041417Z"
        },
        "id": "R3uFXDIH1C2Q"
      },
      "outputs": [],
      "execution_count": 58
    },
    {
      "cell_type": "code",
      "source": [
        "def train(params: Hyperparameters):\n",
        "  # Create model\n",
        "  model = DNN(hidden=params.hidden, dropout_rate=params.dropout_rate).to(device)\n",
        "\n",
        "  class_counts = train_dataset['type'].value_counts()\n",
        "  weights = 1.0 / class_counts.values\n",
        "  weights = torch.FloatTensor(weights).to(device)\n",
        "  criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=params.lr)\n",
        "\n",
        "  # Training loop with early stopping\n",
        "  best_val_loss = float('inf')\n",
        "  patience_counter = 0\n",
        "  epochs_run = params.epochs\n",
        "  for epoch in range(1, params.epochs + 1):\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "      out = model(X_train)\n",
        "      loss = criterion(out, y_train)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss = loss.item()\n",
        "\n",
        "      train_metrics = evaluate(model, X_train, y_train, criterion)\n",
        "      val_metrics = evaluate(model, X_val, y_val, criterion)\n",
        "\n",
        "      if epoch % (params.epochs // 10) == 0:\n",
        "        print(\n",
        "            f\"Epoch {epoch}/{params.epochs} | \"\n",
        "            f\"train_loss={train_loss:.4f} train_acc={train_metrics['accuracy']:.4f} \"\n",
        "            f\"train_f1={train_metrics['f_beta_macro']:.4f} \"\n",
        "            f\"val_loss={val_metrics['loss']:.4f} val_acc={val_metrics['accuracy']:.4f} \"\n",
        "            f\"val_f1={val_metrics['f_beta_macro']:.4f} \"\n",
        "        )\n",
        "\n",
        "      # Early stopping check\n",
        "      if val_metrics['loss'] < best_val_loss:\n",
        "          best_val_loss = val_metrics['loss']\n",
        "          patience_counter = 0\n",
        "      else:\n",
        "          patience_counter += 1\n",
        "          if patience_counter >= params.patience:\n",
        "              print(f\"Early stopping at epoch {epoch}\")\n",
        "              epochs_run = epoch\n",
        "              break\n",
        "\n",
        "  results = {\"epochs_run\": epochs_run,\n",
        "            \"val_loss\": val_metrics[\"loss\"],\n",
        "            \"val_accuracy\": val_metrics[\"accuracy\"],\n",
        "            \"val_f1\": val_metrics[\"f_beta_macro\"],\n",
        "            \"flops\": estimate_flops(model, (1, 32))\n",
        "            }\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T00:43:03.337535Z",
          "iopub.execute_input": "2025-10-17T00:43:03.337852Z",
          "iopub.status.idle": "2025-10-17T00:43:03.676338Z",
          "shell.execute_reply.started": "2025-10-17T00:43:03.337828Z",
          "shell.execute_reply": "2025-10-17T00:43:03.675024Z"
        },
        "id": "pEO7m2r11C2R"
      },
      "outputs": [],
      "execution_count": 78
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the function\n",
        "hyperparameters = Hyperparameters(lr=1e-3, epochs=500, hidden=(64, 32, 16, 8), dropout_rate=0.5, patience=100)\n",
        "result = train(hyperparameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUhJqaHLMxKK",
        "outputId": "f5ae0aa2-8093-4569-db57-8c367a6d46c7"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/500 | train_loss=1.0222 train_acc=0.0677 train_f1=0.0533 val_loss=0.7289 val_acc=0.0678 val_f1=0.0533 \n",
            "Epoch 100/500 | train_loss=0.7891 train_acc=0.4647 train_f1=0.1764 val_loss=0.5583 val_acc=0.4629 val_f1=0.1758 \n",
            "Epoch 150/500 | train_loss=0.6287 train_acc=0.7884 train_f1=0.2895 val_loss=0.4681 val_acc=0.7870 val_f1=0.2890 \n",
            "Epoch 200/500 | train_loss=0.5254 train_acc=0.9150 train_f1=0.3514 val_loss=0.3881 val_acc=0.9137 val_f1=0.3506 \n",
            "Epoch 250/500 | train_loss=0.4564 train_acc=0.9252 train_f1=0.3581 val_loss=0.3146 val_acc=0.9243 val_f1=0.3575 \n",
            "Epoch 300/500 | train_loss=0.4139 train_acc=0.9267 train_f1=0.3590 val_loss=0.2747 val_acc=0.9258 val_f1=0.3583 \n",
            "Epoch 350/500 | train_loss=0.3862 train_acc=0.9285 train_f1=0.3602 val_loss=0.2521 val_acc=0.9277 val_f1=0.3595 \n",
            "Epoch 400/500 | train_loss=0.3653 train_acc=0.9286 train_f1=0.3603 val_loss=0.2391 val_acc=0.9277 val_f1=0.3596 \n",
            "Epoch 450/500 | train_loss=0.3500 train_acc=0.9301 train_f1=0.3612 val_loss=0.2293 val_acc=0.9291 val_f1=0.3605 \n",
            "Epoch 500/500 | train_loss=0.3418 train_acc=0.9315 train_f1=0.3620 val_loss=0.2208 val_acc=0.9303 val_f1=0.3612 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neuroevolution"
      ],
      "metadata": {
        "id": "3_uGubzQTmqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_population(pop_size: int) -> List[Hyperparameters]:\n",
        "    population = []\n",
        "    for _ in range(pop_size):\n",
        "        lr = random.uniform(1e-5, 1e-1)\n",
        "        epochs = random.randint(10, 200)\n",
        "\n",
        "        # Generate variable-length hidden layer tuple\n",
        "        num_layers = random.randint(1, 5)\n",
        "        hidden = tuple(2 ** random.randint(3, 8) for _ in range(num_layers))\n",
        "\n",
        "        dropout_rate = random.uniform(0.0, 0.5)\n",
        "        patience = random.randint(5, 30)\n",
        "\n",
        "        population.append(Hyperparameters(lr, epochs, hidden, dropout_rate, patience))\n",
        "\n",
        "    return population"
      ],
      "metadata": {
        "id": "J3EDsF-zX0b1"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_dominated(fitnesses: List[Tuple[float, ...]], idx: int) -> int:\n",
        "    \"\"\"Count how many points are dominated by fitnesses[idx]\"\"\"\n",
        "    point = fitnesses[idx]\n",
        "    dominated = 0\n",
        "    for other in fitnesses:\n",
        "        if other == point:\n",
        "            continue\n",
        "        # Check if point dominates other (all >= and at least one >)\n",
        "        if all(p >= o for p, o in zip(point, other)) and any(p > o for p, o in zip(point, other)):\n",
        "            dominated += 1\n",
        "    return dominated"
      ],
      "metadata": {
        "id": "JFWFExuUdf6H"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Evolution Strategy to Optimize Hyperparameters"
      ],
      "metadata": {
        "id": "b80BDEmPX5Ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evolution_strategy(mu: int, lambda_: int, tau: float, max_gens: int) -> List[Hyperparameters]:\n",
        "    population = init_population(mu)\n",
        "\n",
        "    for generation_number in range(1, max_gens + 1):\n",
        "        print(f\"Generation {generation_number} starting initial evaluation\")\n",
        "        fitnesses = []\n",
        "        for i, member in enumerate(population):\n",
        "            print(f\"Evaluating member {member[i]}\")\n",
        "            fitnesses.append(train(member))\n",
        "\n",
        "        # fitnesses = [train(member) for member in population]\n",
        "\n",
        "        # Calculate proportion of dominated points for each individual\n",
        "        domination_counts = [count_dominated(fitnesses, i) for i in range(mu)]\n",
        "        domination_proportions = [count / mu for count in domination_counts]\n",
        "\n",
        "        offspring = []\n",
        "        for _ in range(lambda_):\n",
        "            # Select parent using tournament based on domination proportion\n",
        "            candidates = random.sample(range(mu), 2)\n",
        "            parent_idx = max(candidates, key=lambda i: domination_proportions[i])\n",
        "            parent = population[parent_idx]\n",
        "\n",
        "            # Mutate hyperparameters\n",
        "            lr = parent.lr * math.exp(tau * random.gauss(0.0, 1.0))\n",
        "            lr = max(1e-5, min(1e-1, lr))\n",
        "\n",
        "            epochs = int(parent.epochs + random.gauss(0.0, 10))\n",
        "            epochs = max(10, min(500, epochs))\n",
        "\n",
        "            # Mutate hidden layers\n",
        "            hidden = list(parent.hidden)\n",
        "            if random.random() < 0.3:\n",
        "                if len(hidden) > 1 and random.random() < 0.5:\n",
        "                    hidden.pop(random.randrange(len(hidden)))\n",
        "                elif len(hidden) < 5:\n",
        "                    hidden.insert(random.randrange(len(hidden) + 1), 2 ** random.randint(3, 8))\n",
        "            else:\n",
        "                idx = random.randrange(len(hidden))\n",
        "                hidden[idx] = max(8, min(256, int(hidden[idx] + random.gauss(0.0, 16))))\n",
        "\n",
        "            dropout_rate = parent.dropout_rate + random.gauss(0.0, 0.05)\n",
        "            dropout_rate = max(0.0, min(0.5, dropout_rate))\n",
        "\n",
        "            patience = int(parent.patience + random.gauss(0.0, 3))\n",
        "            patience = max(5, min(30, patience))\n",
        "\n",
        "            offspring.append(Hyperparameters(lr, epochs, tuple(hidden), dropout_rate, patience))\n",
        "\n",
        "        offspring_fitnesses = [train(member) for member in offspring]\n",
        "\n",
        "        # Calculate domination for offspring\n",
        "        offspring_domination_counts = [count_dominated(offspring_fitnesses, i) for i in range(lambda_)]\n",
        "        offspring_domination_proportions = [count / lambda_ for count in offspring_domination_counts]\n",
        "\n",
        "        # Logging\n",
        "        best_idx = max(range(mu), key=lambda i: domination_proportions[i])\n",
        "        print(f\"Gen {generation_number} Best: {fitnesses[best_idx]}\")\n",
        "\n",
        "        # Select best member from offspring based on domination\n",
        "        indexed = [(prop, i) for i, prop in enumerate(offspring_domination_proportions)]\n",
        "        indexed.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        population = [offspring[i] for _, i in indexed[:mu]]\n",
        "\n",
        "    return population"
      ],
      "metadata": {
        "id": "-_jNJVH6TmSq"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pop = evolution_strategy(mu=10, lambda_=10, tau=0.05, max_gens=10)\n",
        "for member in final_pop:\n",
        "    print(member)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "g_WgpIjQeQ4n",
        "outputId": "a728028c-0442-478e-e45a-69ae0de2da9c"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1 starting initial evaluation\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'Hyperparameters' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3603381458.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_pop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevolution_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_gens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmember\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinal_pop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-181949236.py\u001b[0m in \u001b[0;36mevolution_strategy\u001b[0;34m(mu, lambda_, tau, max_gens)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmember\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Evaluating member {member[i]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mfitnesses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'Hyperparameters' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test output"
      ],
      "metadata": {
        "id": "WGchc6511C2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y_test = prepare_data(test_dataset, device)\n",
        "\n",
        "# Get predictions\n",
        "with torch.no_grad():\n",
        "    logits = model(X_test)\n",
        "    probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "    predictions = probs.argmax(axis=1)\n",
        "\n",
        "y_true = y_test.cpu().numpy()\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_true, predictions)\n",
        "f_beta = fbeta_score(y_true, predictions, average=\"macro\", beta=2)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test F-Beta (macro): {f_beta:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "wcGqY8qX1C2R"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}